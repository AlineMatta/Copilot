# Copilot
Bootcamp Microsoft Azure - Lab Copilot

PT/BR

Na primeira imagem, como podemos ver é uma receita médica veterinária, anexei ao Copilot e solicitei que me ajudasse a ler e entender a receita e como podemos ver o resultado na pasta Output a resposta que obtive foi excelente. A AI compreendeu a mensagem de texto me informando sobre todos os detalhes descritos na receita, independentemente da escrita á mão, que é tão difícil para nós compreendermos, como: dados pessoais e cadastro do médico veterinário, os dados pessoais do paciente (pet), nome do medicamento e forma (se é pomada, pilula, etc) a quantidade do medicamento a ser fornecida, dosagem, horários, duração do tratamento, data, assinatura do médico veterinário e o carimbo.

Já na segunda imagem, anexei uma caixa de medicamento para pet e solicitei a AI que me informasse o que era aquela imagem e do que se tratava. O resultado foi melhor do que o esperado porque além de conseguir compreender que era um medicamento, ela também informou sobre qual o tipo de medicamento (no caso um anti-inflamatório) e ainda informou qual a matéria-prima (Prednisolona), por fim afirmou que não é uma profissional de saúde e que portanto, deveria-se consultar um veterinário para obter as devidas informações como a forma de uso, dosagem, tratamento, etc.

Conclusão desse Lab é que a AI consegue ser capaz de ler qualquer tipo de documento, imagem, texto, etc e até mesmo escritas á mão, cujas quais muitas vezes temos tantas dificulade em compreender, nos trazendo todas as informações necessárias contidas ou não naquele objeto específico que buscamos informações, inclusive nos trazendo ótimos insights e os links que podem fornecer mais informações, nos auxiliando com problemas, seja qual ele qual for. Também possui um papel super importante aumentando a acessibilidade e a inlcusão, auxiliando pessoas com deficiência ou necessidades especiais a se comunicarem e se expressarem melhor perante a sociedade.

________________________________________________________________________________________________________________________________________________________________________________________

EN/US

In the first image, as we can see it is a veterinary prescription, I attached it to Copilot and I asked him to help me read and understand the recipe and as we can see the result in the Output folder, the response he gave was excellent. The AI ​​understood the text message informing me about all the details described in the prescription, regardless of the handwriting, which is so difficult for us to understand, such as: personal data and registration of the veterinarian, the patient's personal data (pet), name of the medicine and form (if it is an ointment, pill, etc.) the quantity of the medicine to be supplied, dosage, times, duration of treatment, details, signature of the veterinarian and stamp.

In the second image, I attached a pet medicine box and asked the AI ​​to tell me what that image was and what it was about. The result was better than expected because in addition to being able to understand that it was a medicine, she also informed about the type of medicine (in this case an anti-inflammatory) and also informed about the raw material (Prednisolone), finally stating that she is not a health professional and that, therefore, a veterinarian must be consulted to obtain the necessary information such as method of use, dosage, treatment, etc.

The conclusion of this Lab is that AI can be able to read any type of document, image, text, etc. and even handwriting, which we often have so much difficulty understanding, bringing us all the necessary information whether or not contained in that specific object, information we are looking for, including bringing us great insights and links that can provide us with more information, helping us with problems, whatever they may be. It also plays a super important role in increasing accessibility and inclusion, helping people with disabilities or special needs to communicate and express themselves better in society.
